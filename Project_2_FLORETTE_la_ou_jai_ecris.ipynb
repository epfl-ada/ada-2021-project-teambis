{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code de florette (EN COURS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En premier il y a le code pour la comparaison.\n",
    "\n",
    "Aprés il y a plein d'autres trucs qui pourraient être utiles:\n",
    "- des test de tokenisation\n",
    "- des test de formation de n grams\n",
    "- des tests d'utilisation de FastText (il en parle dans le paper dont le nom est marqué u peu plus bas) (c'est un fail)\n",
    "\n",
    "Encore plus bas:\n",
    "- des test de comparaisons sur plein de trucs (random, trus qui se ressemblent, grandes/petites phrases, synonymes) pour voir comment ça marche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnXvjWR9NWvZ"
   },
   "source": [
    "#### Mount the Google Drive in order to access to the files which are located on our drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEcIlRwfWY4C",
    "outputId": "b4c9cb6a-9c53-45c1-ad98-a68c6550c2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive._mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5E6s11nPpS1S"
   },
   "source": [
    "#### Install and import every packages that will be necessary for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDFHjZ-DpMXi",
    "outputId": "5ac51208-9817-41c8-a3c9-d8830978e78d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle-mixin in c:\\users\\flore\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\flore\\anaconda3\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\flore\\anaconda3\\lib\\site-packages (from pyarrow) (1.20.1)\n",
      "Requirement already satisfied: pathlib in c:\\users\\flore\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pickle-mixin\n",
    "!pip install pyarrow\n",
    "!pip install pathlib\n",
    "\n",
    "\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import bz2\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx0MEzbZw5NM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, et import du model qu'on utilise ( pour l'instant all-MiniLM-L6-v2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si besoin\n",
    "#pip install -U sentence-transformers\n",
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEXXUZjT4yN7",
    "outputId": "c638bc74-0576-40b7-b515-a8838a784bc1"
   },
   "outputs": [],
   "source": [
    "#NLP libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#import du model qu'on utilise, je prend all-MiniLM-L6-v2. là j'ai le model en local, mais on eut le prendre direct du net, c'est automoatisé (juste là au moment où je core il y à un bug généralisé, genre plus personne n'y a accès en ligne)\n",
    "model = SentenceTransformer(r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\pretrained_model') #with model all-MiniLM-L6-v2' # or use 'bert-base-nli-mean-tokens'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des citations (morceau par morceau) aux expressions du paper, et création d'un dataframe avec qids, quote, sim_score_expression1, sim_score_expression2, ..., sim_score_expressionN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je decoupe les citations. Pour chaque expression: je compare chaque morceau de la citation avec l'expression, ça donne un score de similarité pour chaque morceau: on prend le max (ou bien faire un teshold ? à voir).  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basé sur la technique du paper Sentence Similarity Techniques for Short vs Variable Length Text using Word Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract a small part of the whole quotes file to test (j'ai pas le vrai fichier pre procéssé, c'est pour ça qu'il y a des [ ] dans les citations, mais ça marchera pareil avec le bon fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a small part of the whole file to test \n",
    "path = r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\quotes-2020-precessed.json.bz2' #path de mon ordi\n",
    "quotes = pd.DataFrame(columns=('qids','quotation'))\n",
    "i = 0\n",
    "with bz2.open(path, 'rb') as s_file:\n",
    "  for instance in s_file:\n",
    "    instance = json.loads(instance) \n",
    "    #print(instance)\n",
    "    #print(instance['quotation'])\n",
    "    i = i + 1\n",
    "    quotes = quotes.append({'quoteID': instance['quoteID'], 'quotation': instance['quotation']}, ignore_index=True)\n",
    "    #print(i)\n",
    "    if i == 10:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a dataframe de test with the expression we want to compare, and their score (remplacer aprés avec le vrai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression</th>\n",
       "      <th>expression_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'dont know</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'suppose</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     expression  expression_score\n",
       "0  I'm not sure              2.91\n",
       "1   I'dont know              3.02\n",
       "2     I'suppose              3.34"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe with the ewpression we want to compare, and their score\n",
    "expressions = pd.DataFrame({'expression': [\"I'm not sure\", \"I'dont know\", \"I'suppose\", \"I'think\", \"I'sure\", \"I'know\"], 'expression_score': [2.91, 3.02, 3.34, 3.48, 6.02, 6.45]})\n",
    "expressions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunker les citations pour découper en un certain nombre de mots (j'ai pas trouvé de méthode optimale, alors je tokenize en mots, puis je join le nombre de mots qu'on veut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quote_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[[, Department, of, Homeland, Security, ], was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[[, I, met, them, ], when, they, just, turned,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17-000357</td>\n",
       "      <td>[[, The, delay, ], will, have, an, impact, [, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             quoteID                                        quote_token\n",
       "0  2020-01-16-000088  [[, Department, of, Homeland, Security, ], was...\n",
       "1  2020-01-24-000168  [[, I, met, them, ], when, they, just, turned,...\n",
       "2  2020-01-17-000357  [[, The, delay, ], will, have, an, impact, [, ..."
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, create dataframe of the expressions tokenized and their confidence score\n",
    "quotes_tokenized = pd.DataFrame(columns = ['quoteID','quote_token'])\n",
    "for index, row in quotes.iterrows():\n",
    "    quotes_tokenized = quotes_tokenized.append({'quoteID': row.quoteID, 'quote_token': nltk.word_tokenize(row.quotation)}, ignore_index=True)\n",
    "quotes_tokenized.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quoteID</th>\n",
       "      <th>quote_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[[ Department of, Department of Homeland, of H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[[ I met, I met them, met them ], them ] when,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17-000357</td>\n",
       "      <td>[[ The delay, The delay ], delay ] will, ] wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-02-000239</td>\n",
       "      <td>[[ The scheme, The scheme ], scheme ] treats, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-19-000276</td>\n",
       "      <td>[[ These ], These ] actions, ] actions will, a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             quoteID                                       quote_chunks\n",
       "0  2020-01-16-000088  [[ Department of, Department of Homeland, of H...\n",
       "1  2020-01-24-000168  [[ I met, I met them, met them ], them ] when,...\n",
       "2  2020-01-17-000357  [[ The delay, The delay ], delay ] will, ] wil...\n",
       "3  2020-04-02-000239  [[ The scheme, The scheme ], scheme ] treats, ...\n",
       "4  2020-03-19-000276  [[ These ], These ] actions, ] actions will, a..."
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then reform chunk of n words\n",
    "\n",
    "n = 4 #number of word in a chunk\n",
    "\n",
    "quotes_chunks = pd.DataFrame(columns = ['quoteID','quote_chunks']) #initialize dataframe \n",
    "\n",
    "\n",
    "for index, row in quotes_tokenized.iterrows():\n",
    "    lenght = len(row.quote_token) \n",
    "    list_chunk = []\n",
    "    for i in range(lenght - n + 1):\n",
    "        chunk = \" \".join(row.quote_token[i : i+n-1])\n",
    "        list_chunk.append(chunk)\n",
    "    #print(list_chunk)\n",
    "    #print('\\n')\n",
    "    quotes_chunks = quotes_chunks.append({'quoteID': row.quoteID, 'quote_chunks': list_chunk}, ignore_index=True)\n",
    "\n",
    "        \n",
    "quotes_chunks.head()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the citations chunk with the expressions and add the comparison score = cosinus similarity (max score for the different chunk) in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qids</th>\n",
       "      <th>quotation</th>\n",
       "      <th>I'm not sure</th>\n",
       "      <th>I'dont know</th>\n",
       "      <th>I'suppose</th>\n",
       "      <th>I'think</th>\n",
       "      <th>I'sure</th>\n",
       "      <th>I'know</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-16-000088</td>\n",
       "      <td>[[ Department of, Department of Homeland, of H...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.199665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-24-000168</td>\n",
       "      <td>[[ I met, I met them, met them ], them ] when,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.249393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17-000357</td>\n",
       "      <td>[[ The delay, The delay ], delay ] will, ] wil...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.336410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-02-000239</td>\n",
       "      <td>[[ The scheme, The scheme ], scheme ] treats, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.294437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-19-000276</td>\n",
       "      <td>[[ These ], These ] actions, ] actions will, a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                qids                                          quotation  \\\n",
       "0  2020-01-16-000088  [[ Department of, Department of Homeland, of H...   \n",
       "1  2020-01-24-000168  [[ I met, I met them, met them ], them ] when,...   \n",
       "2  2020-01-17-000357  [[ The delay, The delay ], delay ] will, ] wil...   \n",
       "3  2020-04-02-000239  [[ The scheme, The scheme ], scheme ] treats, ...   \n",
       "4  2020-03-19-000276  [[ These ], These ] actions, ] actions will, a...   \n",
       "\n",
       "   I'm not sure  I'dont know  I'suppose  I'think  I'sure    I'know  \n",
       "0           NaN          NaN        NaN      NaN     NaN  0.199665  \n",
       "1           NaN          NaN        NaN      NaN     NaN  0.249393  \n",
       "2           NaN          NaN        NaN      NaN     NaN  0.336410  \n",
       "3           NaN          NaN        NaN      NaN     NaN  0.294437  \n",
       "4           NaN          NaN        NaN      NaN     NaN  0.217203  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes_similarity = pd.DataFrame(columns=('qids','quotation', \"I'm not sure\", \"I'dont know\", \"I'suppose\", \"I'think\", \"I'sure\", \"I'know\"))\n",
    "df_max_cos_sim = pd.DataFrame(index=(\"I'm not sure\", \"I'dont know\", \"I'suppose\", \"I'think\", \"I'sure\", \"I'know\"))\n",
    "\n",
    "for index, row in quotes_chunks.iterrows(): #itere sur les citations\n",
    "    \n",
    "    for index_exp, row_exp in expressions.iterrows(): #pour chaque expression\n",
    "        list_cis_sim = [] #list des cosine similarity score pour tous les chunk (on gardera que le max)\n",
    "        exp_to_compare = model.encode(row_exp.expression)\n",
    "        \n",
    "        for chunk in row.quote_chunks: #itere sur les chunk de citation\n",
    "            chunk_to_compare = model.encode(chunk)\n",
    "            cos_sim = cosine_similarity([chunk_to_compare], [exp_to_compare]) #absolument pas sure que je l'utilise comme il faut\n",
    "            #print(cos_sim)\n",
    "            list_cis_sim.append(cos_sim)\n",
    "        \n",
    "    max_cos_sim = max(list_cis_sim)\n",
    "    df_max_cos_sim.loc[row_exp.expression, 0] = max_cos_sim\n",
    "    \n",
    "    quotes_similarity = quotes_similarity.append({'qids': row.quoteID, 'quotation': row.quote_chunks, \"I'm not sure\": df_max_cos_sim.loc[\"I'm not sure\", 0], \"I'dont know\": df_max_cos_sim.loc[\"I'dont know\", 0], \"I'suppose\": df_max_cos_sim.loc[\"I'suppose\", 0], \"I'think\": df_max_cos_sim.loc[\"I'think\", 0], \"I'sure\": df_max_cos_sim.loc[\"I'sure\", 0], \"I'know\": df_max_cos_sim.loc[\"I'know\", 0]}, ignore_index=True)\n",
    "\n",
    "quotes_similarity.head()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I'm not sure</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'dont know</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'suppose</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'think</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'sure</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'know</th>\n",
       "      <td>0.604759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "I'm not sure       NaN\n",
       "I'dont know        NaN\n",
       "I'suppose          NaN\n",
       "I'think            NaN\n",
       "I'sure             NaN\n",
       "I'know        0.604759"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autres trucs que j'ai pas utilisé mais qui peuvent être utile, genre tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenisation of the expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression_token</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I, 'm, not, sure]</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[I'dont, know]</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[I'suppose]</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     expression_token  score\n",
       "0  [I, 'm, not, sure]   2.91\n",
       "1      [I'dont, know]   3.02\n",
       "2         [I'suppose]   3.34"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe of the expressions tokenized and their confidence score\n",
    "expressions_tokenized = pd.DataFrame(columns = ['expression_token', 'score'])\n",
    "for index, row in expressions.iterrows():\n",
    "    expressions_tokenized = expressions_tokenized.append({'expression_token': nltk.word_tokenize(row.expression), 'score': row.expression_score}, ignore_index=True)\n",
    "expressions_tokenized.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenisation of the quotations, en formant des n grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "('[', 'Department', 'of', 'Homeland')\n",
      "('Department', 'of', 'Homeland', 'Security')\n",
      "('of', 'Homeland', 'Security', ']')\n",
      "('Homeland', 'Security', ']', 'was')\n",
      "('Security', ']', 'was', 'livid')\n",
      "(']', 'was', 'livid', 'and')\n",
      "('was', 'livid', 'and', 'strongly')\n",
      "('livid', 'and', 'strongly', 'urged')\n",
      "('and', 'strongly', 'urged', 'to')\n",
      "('strongly', 'urged', 'to', 'have')\n",
      "('urged', 'to', 'have', 'the')\n",
      "('to', 'have', 'the', 'agenda')\n",
      "('have', 'the', 'agenda', 'pulled.')\n",
      "1\n",
      "('[', 'I', 'met', 'them')\n",
      "('I', 'met', 'them', ']')\n",
      "('met', 'them', ']', 'when')\n",
      "('them', ']', 'when', 'they')\n",
      "(']', 'when', 'they', 'just')\n",
      "('when', 'they', 'just', 'turned')\n",
      "('they', 'just', 'turned', '4')\n",
      "('just', 'turned', '4', 'and')\n",
      "('turned', '4', 'and', '7.')\n",
      "('4', 'and', '7.', 'They')\n",
      "('and', '7.', 'They', 'were')\n",
      "('7.', 'They', 'were', 'little.')\n",
      "('They', 'were', 'little.', 'They')\n",
      "('were', 'little.', 'They', 'felt')\n",
      "('little.', 'They', 'felt', 'like')\n",
      "('They', 'felt', 'like', 'my')\n",
      "('felt', 'like', 'my', 'full-blown')\n",
      "('like', 'my', 'full-blown', 'stepkids.')\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "n = 4 # n_gram\n",
    "quotes_n_grams = pd.DataFrame(columns = ['quoteID', 'quote_n_grams'])\n",
    "\n",
    "for index, row in quotes.iterrows():\n",
    "    n_grams = ngrams(row.quotation.split(), n)\n",
    "    quotes_n_grams = quotes_n_grams.append({'quoteID': row.quoteID, 'n_grams': n_grams},  ignore_index=True)\n",
    "    \n",
    "i = 0\n",
    "for index, row in quotes_n_grams.iterrows():\n",
    "    print(i)\n",
    "    i=i+1\n",
    "    for grams in row.n_grams:\n",
    "        print(grams)\n",
    "    if i > 1 : break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trucs randoms, tests, code qui pourrait être utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exemples de truc pour faire des n grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', 'have')\n",
      "('have', 'an')\n",
      "('an', 'apple')\n",
      "('i', 'have', 'an')\n",
      "('have', 'an', 'apple')\n",
      "('i', 'like')\n",
      "('like', 'apples')\n",
      "('apples', 'so')\n",
      "('so', 'much')\n",
      "('i', 'like', 'apples')\n",
      "('like', 'apples', 'so')\n",
      "('apples', 'so', 'much')\n"
     ]
    }
   ],
   "source": [
    "#exemple, not optimal, generate bigram and trigram\n",
    "\n",
    "from nltk import ngrams\n",
    "sentence = ['i have an apple', 'i like apples so much']\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "    for n in range(2, 4):\n",
    "        n_grams = ngrams(sentence[i].split(), n)\n",
    "        for grams in n_grams:\n",
    "            print(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('all', 'this'),\n",
       " ('this', 'happened'),\n",
       " ('happened', 'more'),\n",
       " ('more', 'or'),\n",
       " ('or', 'less')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#autre exemple de generatipn de bigram\n",
    "\n",
    "input_list = ['all', 'this', 'happened', 'more', 'or', 'less']\n",
    "\n",
    "def find_bigrams(input_list):\n",
    "    bigram_list = []\n",
    "    for i in range(len(input_list)-1):\n",
    "        bigram_list.append((input_list[i], input_list[i+1]))\n",
    "    return bigram_list\n",
    "\n",
    "find_bigrams(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test d'utilisation de FastTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install fasttext-win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-e429a28ae085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# English\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cc.en.300.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    ">>> import fasttext.util\n",
    ">>> fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    ">>> ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cc.en.300.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3084270e818b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load pretrained fastText word embeddings python with gensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfasttext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_facebook_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpretrained_fastText_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_facebook_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cc.en.300.bin.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36mload_facebook_model\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \"\"\"\n\u001b[1;32m--> 728\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_load_fasttext_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36m_load_fasttext_format\u001b[1;34m(model_file, encoding, full_model)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m     \"\"\"\n\u001b[1;32m--> 807\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fasttext_bin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mbinary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[0mdecompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mso_compression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[1;34m(uri, mode, transport_params)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[0mscheme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sniff_scheme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[0msubmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m     \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\local_file.py\u001b[0m in \u001b[0;36mopen_uri\u001b[1;34m(uri_as_string, mode, transport_params)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mopen_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mparsed_uri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'uri_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cc.en.300.bin.gz'"
     ]
    }
   ],
   "source": [
    "# Load pretrained fastText word embeddings python with gensim\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "pretrained_fastText_en = load_facebook_model('pretrined fastText model/cc.en.300.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en fait ça c'est pour trained un model, mais c'est pas ce qu'on veut faire ducoup\n",
    "exp_model = FastText(expressions_tokenized.expression_token, vector_size=100, window=4, min_count=1, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_model.wv['computer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests de comparaison : avec des trucs randoms, avec des citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test de comparaison avec des trucs randoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22059387, 0.47637683, 0.22743046]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison semantique avec des trucs randoms\n",
    "\n",
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\pretrained_model') #'bert-base-nli-mean-tokens'\n",
    "\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(\n",
    "    [sentence_embeddings[0]],\n",
    "    sentence_embeddings[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test de comparaison de quelques unes de nos citations entières avec les expressions. \n",
    "\n",
    "Ce n'est pas une bonnemethode, on va devoir découper les phrases en morceau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quoteID': '2020-01-16-000088', 'quotation': '[ Department of Homeland Security ] was livid and strongly urged to have the agenda pulled.', 'speaker': 'Sue Myrick'}\n",
      "{'quoteID': '2020-01-24-000168', 'quotation': '[ I met them ] when they just turned 4 and 7. They were little. They felt like my full-blown stepkids.', 'speaker': 'Meghan King Edmonds'}\n",
      "{'quoteID': '2020-01-17-000357', 'quotation': '[ The delay ] will have an impact [ on Slough ] but that might be mitigated by the fact we are going to have this Western Rail Link to Heathrow. It looks like that may come in sooner than Crossrail.', 'speaker': 'Dexter Smith'}\n",
      "{'quoteID': '2020-04-02-000239', 'quotation': '[ The scheme ] treats addiction as an illness and the results so far have been extremely encouraging.', 'speaker': 'Barry Coppinger'}\n",
      "{'quoteID': '2020-03-19-000276', 'quotation': '[ These ] actions will allow households who have an FHA-insured mortgage to meet the challenges of COVID-19 without fear of losing their homes, and help steady market concerns,', 'speaker': 'Ben Carson'}\n",
      "{'quoteID': '2020-02-02-000235', 'quotation': '... Under a President Biden, the possibilities are endless,', 'speaker': 'Danny Davis'}\n",
      "{'quoteID': '2020-03-12-000358', 'quotation': '1. FM is entitled to go straight to press conference after COBRA + not a surprise. If it annoys you you could suggest to PM he does likewise.', 'speaker': 'Paul Masterton'}\n",
      "{'quoteID': '2020-01-08-000594', 'quotation': '11 straight weeks of pre-season,', 'speaker': 'Aphelele Fassi'}\n",
      "{'quoteID': '2020-02-21-000455', 'quotation': '2019 was a landmark year for Fiverr as we completed a successful IPO, expanded the Fiverr ecosystem with new products, increased our international reach, and most importantly, continued our extraordinary growth momentum and march toward profitability,', 'speaker': 'Micha Kaufman'}\n",
      "{'quoteID': '2020-04-01-000532', 'quotation': \"7pm is when most hospitals change shifts. That's why. We love you heroes.\", 'speaker': 'Amy Schumer'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01433591,  0.02702463,  0.04557954,  0.07573312, -0.02040301,\n",
       "         0.09890234,  0.07345733,  0.0720223 ,  0.02289211,  0.05893324]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison semantique de quelques une de nos citations avec une des phrases types du paper\n",
    "#j'ai fait comme dans un exemple de BERT que j'ai trouvé sur internet. j'ai pris le pretrained model all-MiniLM-L6-v2\n",
    "\n",
    "\n",
    "#note: normalement pas besoin d'avoir le model sur l'ordi, il suffit de mettre le nom 'all-MiniLM-L6-v2' et SentenceTransformer va le chercher tout seul sur internet, mais là il y a un bug genre ajd, \n",
    "#donc j'ai téléchargé le model sur mon ordi et mis le path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\pretrained_model') #with model all-MiniLM-L6-v2' # or use 'bert-base-nli-mean-tokens'\n",
    "\n",
    "\n",
    "#Extract a small part of the whole file to test \n",
    "path = r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\quotes-2020-precessed.json.bz2' #path de mon ordi\n",
    "test = pd.DataFrame(columns=('qids','quotation'))\n",
    "i = 0\n",
    "with bz2.open(path, 'rb') as s_file:\n",
    "  for instance in s_file:\n",
    "    instance = json.loads(instance) \n",
    "    print(instance)\n",
    "    #print(instance['quotation'])\n",
    "    i = i + 1\n",
    "    test = test.append({'quoteID': instance['quoteID'], 'quotation': instance['quotation']}, ignore_index=True)\n",
    "    #print(i)\n",
    "    if i == 10:\n",
    "      break\n",
    "\n",
    "#embedding des 10 citations\n",
    "sentence_embeddings = model.encode(test['quotation'])\n",
    "\n",
    "#comparaison avec une des phrase du paper: cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "to_compare = [\"I'm sure it's\"]\n",
    "to_compare_embedding = model.encode(to_compare)\n",
    "\n",
    "cosine_similarity(\n",
    "    [to_compare_embedding[0]],\n",
    "    sentence_embeddings[0:]\n",
    ")\n",
    "\n",
    "#l'output ets un array des coefficients de similarité (là ils osnt tous ba vu qu'aucune citation n'a un truc prche de I'm sure it's)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encore des tests pour voir si ça marche bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7573065 , 0.02370122, 0.0167593 , 0.07905838, 0.12434015,\n",
       "        0.13122094, 0.01477368, 0.07131456, 0.1100079 , 0.1029016 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison avec le début de la premiere citation pour checker qu'elle a alors bien un score élevé\n",
    "to_compare_2 = [\"Department of Homeland Security was livid and\"]\n",
    "to_compare_2_embedding = model.encode(to_compare_2)\n",
    "\n",
    "cosine_similarity(\n",
    "    [to_compare_2_embedding[0]],\n",
    "    sentence_embeddings[0:]\n",
    ")\n",
    "#le premier est bien plus élevé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17984062]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison avec 2 trucs trés proches\n",
    "to_compare_3 = [\"I'm sure\"]\n",
    "to_compare_3_embedding = model.encode(to_compare_3)\n",
    "sentence_2 = [\"I'm sure it will be OK\"]\n",
    "sentence_2_embedding = model.encode(sentence_2)\n",
    "\n",
    "cosine_similarity(\n",
    "    [to_compare_3_embedding[0]],\n",
    "    sentence_2_embedding[0:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19524246]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison avec 2 synonymes\n",
    "to_compare_3 = [\"I can be wrong\"]\n",
    "to_compare_3_embedding = model.encode(to_compare_3)\n",
    "sentence_2 = [\"I am mistaken coucou love\"] #vrae faf feafq fezfaZF vzev ffreyhju j'ythgz azerazefg rt rt  r zeardcre grtuhy thzrg area etzttrh trhtrbg er ezt ery gt areer fraef dgc r e zger \n",
    "sentence_2_embedding = model.encode(sentence_2)\n",
    "\n",
    "cosine_similarity(\n",
    "    [to_compare_3_embedding[0]],\n",
    "    sentence_2_embedding[0:]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_2_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
