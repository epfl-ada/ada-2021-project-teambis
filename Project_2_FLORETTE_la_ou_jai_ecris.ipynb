{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code de florette (EN COURS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En premier il y a le code pour la comparaison.\n",
    "\n",
    "Aprés il y a plein d'autres trucs qui pourraient être utiles:\n",
    "- des test de tokenisation\n",
    "- des test de formation de n grams\n",
    "- des tests d'utilisation de FastText (il en parle dans le paper dont le nom est marqué u peu plus bas) (c'est un fail)\n",
    "\n",
    "Encore plus bas:\n",
    "- des test de comparaisons sur plein de trucs (random, trus qui se ressemblent, grandes/petites phrases, synonymes) pour voir comment ça marche"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dnXvjWR9NWvZ"
   },
   "source": [
    "#### Mount the Google Drive in order to access to the files which are located on our drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEcIlRwfWY4C",
    "outputId": "b4c9cb6a-9c53-45c1-ad98-a68c6550c2bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive._mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5E6s11nPpS1S"
   },
   "source": [
    "#### Install and import every packages that will be necessary for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDFHjZ-DpMXi",
    "outputId": "5ac51208-9817-41c8-a3c9-d8830978e78d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle-mixin in c:\\users\\flore\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\flore\\anaconda3\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\flore\\anaconda3\\lib\\site-packages (from pyarrow) (1.20.1)\n",
      "Requirement already satisfied: pathlib in c:\\users\\flore\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pickle-mixin\n",
    "!pip install pyarrow\n",
    "!pip install pathlib\n",
    "\n",
    "\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import bz2\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cx0MEzbZw5NM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports, et import du model qu'on utilise ( pour l'instant all-MiniLM-L6-v2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#si besoin\n",
    "#pip install -U sentence-transformers\n",
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEXXUZjT4yN7",
    "outputId": "c638bc74-0576-40b7-b515-a8838a784bc1"
   },
   "outputs": [],
   "source": [
    "#NLP libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#import du model qu'on utilise, je prend all-MiniLM-L6-v2. là j'ai le model en local, mais on eut le prendre direct du net, c'est automoatisé (juste là au moment où je core il y à un bug généralisé, genre plus personne n'y a accès en ligne)\n",
    "#model = SentenceTransformer(r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\pretrained_model') #with model all-MiniLM-L6-v2' # or use 'bert-base-nli-mean-tokens' (deprecated), or 'all-mpnet-base-v2', or 'multi-qa-mpnet-base-dot-v1', 'multi-qa-distilbert-cos-v1'\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# j'ai testé plysieurs models\n",
    "# all-MiniLM-L6-v2: ça passe, treshold à 0.6 ?\n",
    "#all-mpnet-base-v2: ne se télécharge pas\n",
    "#multi-qa-mpnet-base-dot-v1: ne va pas, tous les scores sont trés haut meme pour truc contraires\n",
    "#multi-qa-distilbert-cos-v1: mouai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison des citations (morceau par morceau) aux expressions du paper, et création d'un dataframe avec qids, quote, sim_score_expression1, sim_score_expression2, ..., sim_score_expressionN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Je decoupe les citations. Pour chaque expression: je compare chaque morceau de la citation avec l'expression, ça donne un score de similarité pour chaque morceau: on prend le max (ou bien faire un teshold ? à voir).  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basé sur la technique du paper Sentence Similarity Techniques for Short vs Variable Length Text using Word Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract a small part of the whole quotes file to test (j'ai pas le vrai fichier pre procéssé, c'est pour ça qu'il y a des [ ] dans les citations, mais ça marchera pareil avec le bon fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a small part of the whole file to test \n",
    "path = r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\quotes-processed.json.bz2' #path de mon ordi\n",
    "quotes = pd.DataFrame(columns=('qids','quotation'))\n",
    "i = 0\n",
    "with bz2.open(path, 'rb') as s_file:\n",
    "  for instance in s_file:\n",
    "    instance = json.loads(instance) \n",
    "    #print(instance)\n",
    "    #print(instance['quotation'])\n",
    "    i = i + 1\n",
    "    quotes = quotes.append({'qids': instance['qids'], 'quotation': instance['quotation']}, ignore_index=True)\n",
    "    #print(i)\n",
    "    if i == 10:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### append some quotation for testing the efficacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = quotes.append({'qids': 'Qtest1', 'quotation': 'I know it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest2', 'quotation': 'I dont know if it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest3', 'quotation': 'I am sure it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest4', 'quotation': 'I am not sure if it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest5', 'quotation': 'I dont eat an apple'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest6', 'quotation': 'I pretty sure if it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest7', 'quotation': 'I was sure if it is a fool'}, ignore_index=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### create a dataframe de test with the expression we want to compare, and their score (remplacer aprés avec le vrai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression</th>\n",
       "      <th>expression_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dont know</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I suppose</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     expression  expression_score\n",
       "0  I'm not sure              2.91\n",
       "1   I dont know              3.02\n",
       "2     I suppose              3.34"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe with the ewpression we want to compare, and their score\n",
    "expressions = pd.DataFrame({'expression': [\"I'm not sure\", \"I dont know\", \"I suppose\", \"I think\", \"I'm sure\", \"I know\"], 'expression_score': [2.91, 3.02, 3.34, 3.48, 6.02, 6.45]})\n",
    "expressions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chunker les citations pour découper en un certain nombre de mots (j'ai pas trouvé de méthode optimale, alors je tokenize en mots, puis je join le nombre de mots qu'on veut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qids</th>\n",
       "      <th>quote_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>[Department, of, Homeland, Security, was, livi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>[I, met, them, when, they, just, turned, 4, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>[The, delay, will, have, an, impact, on, Sloug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qids                                        quote_token\n",
       "0    [Q367796]  [Department, of, Homeland, Security, was, livi...\n",
       "1  [Q20684375]  [I, met, them, when, they, just, turned, 4, an...\n",
       "2   [Q5268447]  [The, delay, will, have, an, impact, on, Sloug..."
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First, create dataframe of the expressions tokenized and their confidence score\n",
    "quotes_tokenized = pd.DataFrame(columns = ['qids','quote_token'])\n",
    "for index, row in quotes.iterrows():\n",
    "    quotes_tokenized = quotes_tokenized.append({'qids': row.qids, 'quote_token': nltk.word_tokenize(row.quotation)}, ignore_index=True)\n",
    "quotes_tokenized.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qids</th>\n",
       "      <th>quote_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>[Department of Homeland, of Homeland Security,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>[I met them, met them when, them when they, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>[The delay will, delay will have, will have an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Q4864119]</td>\n",
       "      <td>[The scheme treats, scheme treats addiction, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Q816459]</td>\n",
       "      <td>[These actions will, actions will allow, will ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          qids                                       quote_chunks\n",
       "0    [Q367796]  [Department of Homeland, of Homeland Security,...\n",
       "1  [Q20684375]  [I met them, met them when, them when they, wh...\n",
       "2   [Q5268447]  [The delay will, delay will have, will have an...\n",
       "3   [Q4864119]  [The scheme treats, scheme treats addiction, t...\n",
       "4    [Q816459]  [These actions will, actions will allow, will ..."
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Then reform chunk of n words\n",
    "\n",
    "n = 4 #number of word in a chunk\n",
    "\n",
    "quotes_chunks = pd.DataFrame(columns = ['qids','quote_chunks']) #initialize dataframe \n",
    "\n",
    "\n",
    "for index, row in quotes_tokenized.iterrows():\n",
    "    lenght = len(row.quote_token) \n",
    "    list_chunk = []\n",
    "    for i in range(lenght - n + 1):\n",
    "        chunk = \" \".join(row.quote_token[i : i+n-1])\n",
    "        list_chunk.append(chunk)\n",
    "    #print(list_chunk)\n",
    "    #print('\\n')\n",
    "    quotes_chunks = quotes_chunks.append({'qids': row.qids, 'quote_chunks': list_chunk}, ignore_index=True)\n",
    "\n",
    "        \n",
    "quotes_chunks.head()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the citations chunk with the expressions and add the comparison score = cosinus similarity (max score for the different chunk) in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_similarity = pd.DataFrame(columns=('qids','quotation', \"I'm not sure\", \"I dont know\", \"I suppose\", \"I think\", \"I'm sure\", \"I know\"))\n",
    "df_max_cos_sim = pd.DataFrame(index=(\"I'm not sure\", \"I dont know\", \"I suppose\", \"I think\", \"I'm sure\", \"I know\"))\n",
    "\n",
    "for index, row in quotes_chunks.iterrows(): #itere sur les citations\n",
    "    \n",
    "    for index_exp, row_exp in expressions.iterrows(): #pour chaque expression\n",
    "        list_cis_sim = [] #list des cosine similarity score pour tous les chunk (on gardera que le max)\n",
    "        exp_to_compare = model.encode(row_exp.expression)\n",
    "        \n",
    "        for chunk in row.quote_chunks: #itere sur les chunk de citation\n",
    "            chunk_to_compare = model.encode(chunk)\n",
    "            cos_sim = cosine_similarity([chunk_to_compare], [exp_to_compare]) #absolument pas sure que je l'utilise comme il faut\n",
    "            #print(cos_sim)\n",
    "            list_cis_sim.append(cos_sim)\n",
    "        \n",
    "        max_cos_sim = max(list_cis_sim)\n",
    "        df_max_cos_sim.loc[row_exp.expression, 0] = max_cos_sim\n",
    "    \n",
    "    quotes_similarity = quotes_similarity.append({'qids': row.qids, 'quotation': row.quote_chunks, \"I'm not sure\": df_max_cos_sim.loc[\"I'm not sure\", 0], \"I dont know\": df_max_cos_sim.loc[\"I dont know\", 0], \"I suppose\": df_max_cos_sim.loc[\"I suppose\", 0], \"I think\": df_max_cos_sim.loc[\"I think\", 0], \"I'm sure\": df_max_cos_sim.loc[\"I'm sure\", 0], \"I know\": df_max_cos_sim.loc[\"I know\", 0]}, ignore_index=True)\n",
    "\n",
    "#quotes_similarity.head(12)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qids</th>\n",
       "      <th>quotation</th>\n",
       "      <th>I'm not sure</th>\n",
       "      <th>I dont know</th>\n",
       "      <th>I suppose</th>\n",
       "      <th>I think</th>\n",
       "      <th>I'm sure</th>\n",
       "      <th>I know</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qtest1</td>\n",
       "      <td>[I know it, know it is, it is a]</td>\n",
       "      <td>0.287719</td>\n",
       "      <td>0.251294</td>\n",
       "      <td>0.306325</td>\n",
       "      <td>0.366793</td>\n",
       "      <td>0.391116</td>\n",
       "      <td>0.818253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qtest2</td>\n",
       "      <td>[I dont know, dont know if, know if it, if it ...</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420749</td>\n",
       "      <td>0.447580</td>\n",
       "      <td>0.437839</td>\n",
       "      <td>0.355956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qtest3</td>\n",
       "      <td>[I am sure, am sure it, sure it is, it is a]</td>\n",
       "      <td>0.525282</td>\n",
       "      <td>0.418564</td>\n",
       "      <td>0.560582</td>\n",
       "      <td>0.469052</td>\n",
       "      <td>0.946308</td>\n",
       "      <td>0.458801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qtest4</td>\n",
       "      <td>[I am not, am not sure, not sure if, sure if i...</td>\n",
       "      <td>0.850227</td>\n",
       "      <td>0.683103</td>\n",
       "      <td>0.390731</td>\n",
       "      <td>0.468090</td>\n",
       "      <td>0.503178</td>\n",
       "      <td>0.344952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qtest5</td>\n",
       "      <td>[I dont eat, dont eat an]</td>\n",
       "      <td>0.161471</td>\n",
       "      <td>0.195348</td>\n",
       "      <td>0.100146</td>\n",
       "      <td>0.065757</td>\n",
       "      <td>0.159083</td>\n",
       "      <td>0.224308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qtest6</td>\n",
       "      <td>[I pretty sure, pretty sure if, sure if it, if...</td>\n",
       "      <td>0.630606</td>\n",
       "      <td>0.520012</td>\n",
       "      <td>0.644584</td>\n",
       "      <td>0.654895</td>\n",
       "      <td>0.793351</td>\n",
       "      <td>0.344952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Qtest7</td>\n",
       "      <td>[I was sure, was sure if, sure if it, if it is...</td>\n",
       "      <td>0.428967</td>\n",
       "      <td>0.295433</td>\n",
       "      <td>0.419736</td>\n",
       "      <td>0.366793</td>\n",
       "      <td>0.767583</td>\n",
       "      <td>0.485900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      qids                                          quotation  I'm not sure  \\\n",
       "10  Qtest1                   [I know it, know it is, it is a]      0.287719   \n",
       "11  Qtest2  [I dont know, dont know if, know if it, if it ...      0.759200   \n",
       "12  Qtest3       [I am sure, am sure it, sure it is, it is a]      0.525282   \n",
       "13  Qtest4  [I am not, am not sure, not sure if, sure if i...      0.850227   \n",
       "14  Qtest5                          [I dont eat, dont eat an]      0.161471   \n",
       "15  Qtest6  [I pretty sure, pretty sure if, sure if it, if...      0.630606   \n",
       "16  Qtest7  [I was sure, was sure if, sure if it, if it is...      0.428967   \n",
       "\n",
       "    I dont know  I suppose   I think  I'm sure    I know  \n",
       "10     0.251294   0.306325  0.366793  0.391116  0.818253  \n",
       "11     1.000000   0.420749  0.447580  0.437839  0.355956  \n",
       "12     0.418564   0.560582  0.469052  0.946308  0.458801  \n",
       "13     0.683103   0.390731  0.468090  0.503178  0.344952  \n",
       "14     0.195348   0.100146  0.065757  0.159083  0.224308  \n",
       "15     0.520012   0.644584  0.654895  0.793351  0.344952  \n",
       "16     0.295433   0.419736  0.366793  0.767583  0.485900  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(quotes_similarity.iloc[10:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qids</th>\n",
       "      <th>quotation</th>\n",
       "      <th>I'm not sure</th>\n",
       "      <th>I'dont know</th>\n",
       "      <th>I'suppose</th>\n",
       "      <th>I'think</th>\n",
       "      <th>I'sure</th>\n",
       "      <th>I'know</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>[Department of Homeland, of Homeland Security,...</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.297696</td>\n",
       "      <td>0.217772</td>\n",
       "      <td>0.228274</td>\n",
       "      <td>0.242716</td>\n",
       "      <td>0.199665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>[I met them, met them when, them when they, wh...</td>\n",
       "      <td>0.230303</td>\n",
       "      <td>0.233470</td>\n",
       "      <td>0.266534</td>\n",
       "      <td>0.275259</td>\n",
       "      <td>0.261234</td>\n",
       "      <td>0.249393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>[The delay will, delay will have, will have an...</td>\n",
       "      <td>0.412485</td>\n",
       "      <td>0.323660</td>\n",
       "      <td>0.517528</td>\n",
       "      <td>0.621261</td>\n",
       "      <td>0.326985</td>\n",
       "      <td>0.336410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Q4864119]</td>\n",
       "      <td>[The scheme treats, scheme treats addiction, t...</td>\n",
       "      <td>0.272484</td>\n",
       "      <td>0.241025</td>\n",
       "      <td>0.238938</td>\n",
       "      <td>0.254450</td>\n",
       "      <td>0.240250</td>\n",
       "      <td>0.294437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Q816459]</td>\n",
       "      <td>[These actions will, actions will allow, will ...</td>\n",
       "      <td>0.283460</td>\n",
       "      <td>0.298020</td>\n",
       "      <td>0.223775</td>\n",
       "      <td>0.182380</td>\n",
       "      <td>0.205218</td>\n",
       "      <td>0.217203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Q30164281]</td>\n",
       "      <td>[1 . FM, . FM is, FM is entitled, is entitled ...</td>\n",
       "      <td>0.292810</td>\n",
       "      <td>0.238106</td>\n",
       "      <td>0.322083</td>\n",
       "      <td>0.251693</td>\n",
       "      <td>0.361709</td>\n",
       "      <td>0.255408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Q56255401]</td>\n",
       "      <td>[11 straight weeks, straight weeks of, weeks o...</td>\n",
       "      <td>0.185044</td>\n",
       "      <td>0.168329</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.201659</td>\n",
       "      <td>0.170129</td>\n",
       "      <td>0.179680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Q26923564]</td>\n",
       "      <td>[2019 was a, was a landmark, a landmark year, ...</td>\n",
       "      <td>0.239804</td>\n",
       "      <td>0.236918</td>\n",
       "      <td>0.169898</td>\n",
       "      <td>0.239955</td>\n",
       "      <td>0.213944</td>\n",
       "      <td>0.205041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Q4749380]</td>\n",
       "      <td>[7pm is when, is when most, when most hospital...</td>\n",
       "      <td>0.269845</td>\n",
       "      <td>0.314072</td>\n",
       "      <td>0.339756</td>\n",
       "      <td>0.267074</td>\n",
       "      <td>0.492714</td>\n",
       "      <td>0.604759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Q970000]</td>\n",
       "      <td>[A city is, city is not, is not an, not an acc...</td>\n",
       "      <td>0.310569</td>\n",
       "      <td>0.282475</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>0.236583</td>\n",
       "      <td>0.201255</td>\n",
       "      <td>0.277545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qtest1</td>\n",
       "      <td>[I know it, know it is, it is a]</td>\n",
       "      <td>0.287719</td>\n",
       "      <td>0.236971</td>\n",
       "      <td>0.258935</td>\n",
       "      <td>0.321105</td>\n",
       "      <td>0.385404</td>\n",
       "      <td>0.757066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qtest2</td>\n",
       "      <td>[I dont know, dont know if, know if it, if it ...</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>0.948354</td>\n",
       "      <td>0.435690</td>\n",
       "      <td>0.471933</td>\n",
       "      <td>0.339050</td>\n",
       "      <td>0.356231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qtest3</td>\n",
       "      <td>[I am sure, am sure it, sure it is, it is a]</td>\n",
       "      <td>0.525282</td>\n",
       "      <td>0.412137</td>\n",
       "      <td>0.546826</td>\n",
       "      <td>0.495713</td>\n",
       "      <td>0.730975</td>\n",
       "      <td>0.471767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qtest4</td>\n",
       "      <td>[I am not, am not sure, not sure if, sure if i...</td>\n",
       "      <td>0.850227</td>\n",
       "      <td>0.631784</td>\n",
       "      <td>0.388947</td>\n",
       "      <td>0.441323</td>\n",
       "      <td>0.554917</td>\n",
       "      <td>0.328604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qtest5</td>\n",
       "      <td>[I dont eat, dont eat an]</td>\n",
       "      <td>0.161471</td>\n",
       "      <td>0.221329</td>\n",
       "      <td>0.105794</td>\n",
       "      <td>0.077103</td>\n",
       "      <td>0.181148</td>\n",
       "      <td>0.215941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qtest6</td>\n",
       "      <td>[I pretty sure, pretty sure if, sure if it, if...</td>\n",
       "      <td>0.630606</td>\n",
       "      <td>0.502553</td>\n",
       "      <td>0.639852</td>\n",
       "      <td>0.684055</td>\n",
       "      <td>0.585420</td>\n",
       "      <td>0.349950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Qtest1</td>\n",
       "      <td>[I know it, know it is, it is a]</td>\n",
       "      <td>0.287719</td>\n",
       "      <td>0.236971</td>\n",
       "      <td>0.258935</td>\n",
       "      <td>0.321105</td>\n",
       "      <td>0.385404</td>\n",
       "      <td>0.757066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Qtest2</td>\n",
       "      <td>[I dont know, dont know if, know if it, if it ...</td>\n",
       "      <td>0.759200</td>\n",
       "      <td>0.948354</td>\n",
       "      <td>0.435690</td>\n",
       "      <td>0.471933</td>\n",
       "      <td>0.339050</td>\n",
       "      <td>0.356231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Qtest3</td>\n",
       "      <td>[I am sure, am sure it, sure it is, it is a]</td>\n",
       "      <td>0.525282</td>\n",
       "      <td>0.412137</td>\n",
       "      <td>0.546826</td>\n",
       "      <td>0.495713</td>\n",
       "      <td>0.730975</td>\n",
       "      <td>0.471767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Qtest4</td>\n",
       "      <td>[I am not, am not sure, not sure if, sure if i...</td>\n",
       "      <td>0.850227</td>\n",
       "      <td>0.631784</td>\n",
       "      <td>0.388947</td>\n",
       "      <td>0.441323</td>\n",
       "      <td>0.554917</td>\n",
       "      <td>0.328604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           qids                                          quotation  \\\n",
       "0     [Q367796]  [Department of Homeland, of Homeland Security,...   \n",
       "1   [Q20684375]  [I met them, met them when, them when they, wh...   \n",
       "2    [Q5268447]  [The delay will, delay will have, will have an...   \n",
       "3    [Q4864119]  [The scheme treats, scheme treats addiction, t...   \n",
       "4     [Q816459]  [These actions will, actions will allow, will ...   \n",
       "5   [Q30164281]  [1 . FM, . FM is, FM is entitled, is entitled ...   \n",
       "6   [Q56255401]  [11 straight weeks, straight weeks of, weeks o...   \n",
       "7   [Q26923564]  [2019 was a, was a landmark, a landmark year, ...   \n",
       "8    [Q4749380]  [7pm is when, is when most, when most hospital...   \n",
       "9     [Q970000]  [A city is, city is not, is not an, not an acc...   \n",
       "10       Qtest1                   [I know it, know it is, it is a]   \n",
       "11       Qtest2  [I dont know, dont know if, know if it, if it ...   \n",
       "12       Qtest3       [I am sure, am sure it, sure it is, it is a]   \n",
       "13       Qtest4  [I am not, am not sure, not sure if, sure if i...   \n",
       "14       Qtest5                          [I dont eat, dont eat an]   \n",
       "15       Qtest6  [I pretty sure, pretty sure if, sure if it, if...   \n",
       "16       Qtest1                   [I know it, know it is, it is a]   \n",
       "17       Qtest2  [I dont know, dont know if, know if it, if it ...   \n",
       "18       Qtest3       [I am sure, am sure it, sure it is, it is a]   \n",
       "19       Qtest4  [I am not, am not sure, not sure if, sure if i...   \n",
       "\n",
       "    I'm not sure  I'dont know  I'suppose   I'think    I'sure    I'know  \n",
       "0       0.303232     0.297696   0.217772  0.228274  0.242716  0.199665  \n",
       "1       0.230303     0.233470   0.266534  0.275259  0.261234  0.249393  \n",
       "2       0.412485     0.323660   0.517528  0.621261  0.326985  0.336410  \n",
       "3       0.272484     0.241025   0.238938  0.254450  0.240250  0.294437  \n",
       "4       0.283460     0.298020   0.223775  0.182380  0.205218  0.217203  \n",
       "5       0.292810     0.238106   0.322083  0.251693  0.361709  0.255408  \n",
       "6       0.185044     0.168329   0.139400  0.201659  0.170129  0.179680  \n",
       "7       0.239804     0.236918   0.169898  0.239955  0.213944  0.205041  \n",
       "8       0.269845     0.314072   0.339756  0.267074  0.492714  0.604759  \n",
       "9       0.310569     0.282475   0.228700  0.236583  0.201255  0.277545  \n",
       "10      0.287719     0.236971   0.258935  0.321105  0.385404  0.757066  \n",
       "11      0.759200     0.948354   0.435690  0.471933  0.339050  0.356231  \n",
       "12      0.525282     0.412137   0.546826  0.495713  0.730975  0.471767  \n",
       "13      0.850227     0.631784   0.388947  0.441323  0.554917  0.328604  \n",
       "14      0.161471     0.221329   0.105794  0.077103  0.181148  0.215941  \n",
       "15      0.630606     0.502553   0.639852  0.684055  0.585420  0.349950  \n",
       "16      0.287719     0.236971   0.258935  0.321105  0.385404  0.757066  \n",
       "17      0.759200     0.948354   0.435690  0.471933  0.339050  0.356231  \n",
       "18      0.525282     0.412137   0.546826  0.495713  0.730975  0.471767  \n",
       "19      0.850227     0.631784   0.388947  0.441323  0.554917  0.328604  "
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#avec le premier model testé, NE PAS RUNNER !!!!!!!!!!!!!\n",
    "quotes_similarity.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-185-7dffd709778c>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-185-7dffd709778c>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    #display(row)\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "for index, row in quotes_similarity.iterrows():\n",
    "    #display(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I'm not sure</th>\n",
       "      <td>0.269845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'dont know</th>\n",
       "      <td>0.314072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'suppose</th>\n",
       "      <td>0.339756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'think</th>\n",
       "      <td>0.267074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'sure</th>\n",
       "      <td>0.492714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I'know</th>\n",
       "      <td>0.604759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0\n",
       "I'm not sure  0.269845\n",
       "I'dont know   0.314072\n",
       "I'suppose     0.339756\n",
       "I'think       0.267074\n",
       "I'sure        0.492714\n",
       "I'know        0.604759"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_max_cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The delay will have an impact on Slough but that might be mitigated by the fact we are going to have this Western Rail Link to Heathrow. It looks like that may come in sooner than Crossrail.'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quotes.quotation.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes_chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autres trucs que j'ai pas utilisé mais qui peuvent être utile, genre tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenisation of the expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression_token</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[I, 'm, not, sure]</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[I'dont, know]</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[I'suppose]</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     expression_token  score\n",
       "0  [I, 'm, not, sure]   2.91\n",
       "1      [I'dont, know]   3.02\n",
       "2         [I'suppose]   3.34"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe of the expressions tokenized and their confidence score\n",
    "expressions_tokenized = pd.DataFrame(columns = ['expression_token', 'score'])\n",
    "for index, row in expressions.iterrows():\n",
    "    expressions_tokenized = expressions_tokenized.append({'expression_token': nltk.word_tokenize(row.expression), 'score': row.expression_score}, ignore_index=True)\n",
    "expressions_tokenized.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenisation of the quotations, en formant des n grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "('[', 'Department', 'of', 'Homeland')\n",
      "('Department', 'of', 'Homeland', 'Security')\n",
      "('of', 'Homeland', 'Security', ']')\n",
      "('Homeland', 'Security', ']', 'was')\n",
      "('Security', ']', 'was', 'livid')\n",
      "(']', 'was', 'livid', 'and')\n",
      "('was', 'livid', 'and', 'strongly')\n",
      "('livid', 'and', 'strongly', 'urged')\n",
      "('and', 'strongly', 'urged', 'to')\n",
      "('strongly', 'urged', 'to', 'have')\n",
      "('urged', 'to', 'have', 'the')\n",
      "('to', 'have', 'the', 'agenda')\n",
      "('have', 'the', 'agenda', 'pulled.')\n",
      "1\n",
      "('[', 'I', 'met', 'them')\n",
      "('I', 'met', 'them', ']')\n",
      "('met', 'them', ']', 'when')\n",
      "('them', ']', 'when', 'they')\n",
      "(']', 'when', 'they', 'just')\n",
      "('when', 'they', 'just', 'turned')\n",
      "('they', 'just', 'turned', '4')\n",
      "('just', 'turned', '4', 'and')\n",
      "('turned', '4', 'and', '7.')\n",
      "('4', 'and', '7.', 'They')\n",
      "('and', '7.', 'They', 'were')\n",
      "('7.', 'They', 'were', 'little.')\n",
      "('They', 'were', 'little.', 'They')\n",
      "('were', 'little.', 'They', 'felt')\n",
      "('little.', 'They', 'felt', 'like')\n",
      "('They', 'felt', 'like', 'my')\n",
      "('felt', 'like', 'my', 'full-blown')\n",
      "('like', 'my', 'full-blown', 'stepkids.')\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "n = 4 # n_gram\n",
    "quotes_n_grams = pd.DataFrame(columns = ['quoteID', 'quote_n_grams'])\n",
    "\n",
    "for index, row in quotes.iterrows():\n",
    "    n_grams = ngrams(row.quotation.split(), n)\n",
    "    quotes_n_grams = quotes_n_grams.append({'quoteID': row.quoteID, 'n_grams': n_grams},  ignore_index=True)\n",
    "    \n",
    "i = 0\n",
    "for index, row in quotes_n_grams.iterrows():\n",
    "    print(i)\n",
    "    i=i+1\n",
    "    for grams in row.n_grams:\n",
    "        print(grams)\n",
    "    if i > 1 : break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trucs randoms, tests, code qui pourrait être utiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### exemples de truc pour faire des n grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', 'have')\n",
      "('have', 'an')\n",
      "('an', 'apple')\n",
      "('i', 'have', 'an')\n",
      "('have', 'an', 'apple')\n",
      "('i', 'like')\n",
      "('like', 'apples')\n",
      "('apples', 'so')\n",
      "('so', 'much')\n",
      "('i', 'like', 'apples')\n",
      "('like', 'apples', 'so')\n",
      "('apples', 'so', 'much')\n"
     ]
    }
   ],
   "source": [
    "#exemple, not optimal, generate bigram and trigram\n",
    "\n",
    "from nltk import ngrams\n",
    "sentence = ['i have an apple', 'i like apples so much']\n",
    "\n",
    "for i in range(len(sentence)):\n",
    "    for n in range(2, 4):\n",
    "        n_grams = ngrams(sentence[i].split(), n)\n",
    "        for grams in n_grams:\n",
    "            print(grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('all', 'this'),\n",
       " ('this', 'happened'),\n",
       " ('happened', 'more'),\n",
       " ('more', 'or'),\n",
       " ('or', 'less')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#autre exemple de generatipn de bigram\n",
    "\n",
    "input_list = ['all', 'this', 'happened', 'more', 'or', 'less']\n",
    "\n",
    "def find_bigrams(input_list):\n",
    "    bigram_list = []\n",
    "    for i in range(len(input_list)-1):\n",
    "        bigram_list.append((input_list[i], input_list[i+1]))\n",
    "    return bigram_list\n",
    "\n",
    "find_bigrams(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test d'utilisation de FastTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install fasttext-win"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fasttext'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-e429a28ae085>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mif_exists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# English\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfasttext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cc.en.300.bin'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fasttext'"
     ]
    }
   ],
   "source": [
    ">>> import fasttext.util\n",
    ">>> fasttext.util.download_model('en', if_exists='ignore')  # English\n",
    ">>> ft = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'cc.en.300.bin.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3084270e818b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load pretrained fastText word embeddings python with gensim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfasttext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_facebook_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpretrained_fastText_en\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_facebook_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cc.en.300.bin.gz'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36mload_facebook_model\u001b[1;34m(path, encoding)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \"\"\"\n\u001b[1;32m--> 728\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_load_fasttext_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\gensim\\models\\fasttext.py\u001b[0m in \u001b[0;36m_load_fasttext_format\u001b[1;34m(model_file, encoding, full_model)\u001b[0m\n\u001b[0;32m    805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m     \"\"\"\n\u001b[1;32m--> 807\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fasttext_bin\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfull_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfull_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, compression, transport_params)\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mve\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m     \u001b[0mbinary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_binary_stream\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    236\u001b[0m     \u001b[0mdecompressed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mso_compression\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompression_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py\u001b[0m in \u001b[0;36m_open_binary_stream\u001b[1;34m(uri, mode, transport_params)\u001b[0m\n\u001b[0;32m    396\u001b[0m     \u001b[0mscheme\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sniff_scheme\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[0msubmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_transport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscheme\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m     \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m         \u001b[0mfobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muri\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\smart_open\\local_file.py\u001b[0m in \u001b[0;36mopen_uri\u001b[1;34m(uri_as_string, mode, transport_params)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mopen_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransport_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mparsed_uri\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri_as_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mfobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'uri_path'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'cc.en.300.bin.gz'"
     ]
    }
   ],
   "source": [
    "# Load pretrained fastText word embeddings python with gensim\n",
    "from gensim.models.fasttext import load_facebook_model\n",
    "pretrained_fastText_en = load_facebook_model('pretrined fastText model/cc.en.300.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en fait ça c'est pour trained un model, mais c'est pas ce qu'on veut faire ducoup\n",
    "exp_model = FastText(expressions_tokenized.expression_token, vector_size=100, window=4, min_count=1, workers=4,sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exp_model.wv['computer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests de comparaison : avec des trucs randoms, avec des citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test de comparaison avec des trucs randoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22059387, 0.47637683, 0.22743046]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison semantique avec des trucs randoms\n",
    "\n",
    "sentences = [\n",
    "    \"Three years later, the coffin was still full of Jello.\",\n",
    "    \"The fish dreamed of escaping the fishbowl and into the toilet where he saw his friend go.\",\n",
    "    \"The person box was packed with jelly many dozens of months later.\",\n",
    "    \"He found a leprechaun in his walnut shell.\"\n",
    "]\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\pretrained_model') #'bert-base-nli-mean-tokens'\n",
    "\n",
    "sentence_embeddings = model.encode(sentences)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarity(\n",
    "    [sentence_embeddings[0]],\n",
    "    sentence_embeddings[1:]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### test de comparaison de quelques unes de nos citations entières avec les expressions. \n",
    "\n",
    "Ce n'est pas une bonnemethode, on va devoir découper les phrases en morceau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'quoteID': '2020-01-16-000088', 'quotation': '[ Department of Homeland Security ] was livid and strongly urged to have the agenda pulled.', 'speaker': 'Sue Myrick'}\n",
      "{'quoteID': '2020-01-24-000168', 'quotation': '[ I met them ] when they just turned 4 and 7. They were little. They felt like my full-blown stepkids.', 'speaker': 'Meghan King Edmonds'}\n",
      "{'quoteID': '2020-01-17-000357', 'quotation': '[ The delay ] will have an impact [ on Slough ] but that might be mitigated by the fact we are going to have this Western Rail Link to Heathrow. It looks like that may come in sooner than Crossrail.', 'speaker': 'Dexter Smith'}\n",
      "{'quoteID': '2020-04-02-000239', 'quotation': '[ The scheme ] treats addiction as an illness and the results so far have been extremely encouraging.', 'speaker': 'Barry Coppinger'}\n",
      "{'quoteID': '2020-03-19-000276', 'quotation': '[ These ] actions will allow households who have an FHA-insured mortgage to meet the challenges of COVID-19 without fear of losing their homes, and help steady market concerns,', 'speaker': 'Ben Carson'}\n",
      "{'quoteID': '2020-02-02-000235', 'quotation': '... Under a President Biden, the possibilities are endless,', 'speaker': 'Danny Davis'}\n",
      "{'quoteID': '2020-03-12-000358', 'quotation': '1. FM is entitled to go straight to press conference after COBRA + not a surprise. If it annoys you you could suggest to PM he does likewise.', 'speaker': 'Paul Masterton'}\n",
      "{'quoteID': '2020-01-08-000594', 'quotation': '11 straight weeks of pre-season,', 'speaker': 'Aphelele Fassi'}\n",
      "{'quoteID': '2020-02-21-000455', 'quotation': '2019 was a landmark year for Fiverr as we completed a successful IPO, expanded the Fiverr ecosystem with new products, increased our international reach, and most importantly, continued our extraordinary growth momentum and march toward profitability,', 'speaker': 'Micha Kaufman'}\n",
      "{'quoteID': '2020-04-01-000532', 'quotation': \"7pm is when most hospitals change shifts. That's why. We love you heroes.\", 'speaker': 'Amy Schumer'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.01433591,  0.02702463,  0.04557954,  0.07573312, -0.02040301,\n",
       "         0.09890234,  0.07345733,  0.0720223 ,  0.02289211,  0.05893324]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison semantique de quelques une de nos citations avec une des phrases types du paper\n",
    "#j'ai fait comme dans un exemple de BERT que j'ai trouvé sur internet. j'ai pris le pretrained model all-MiniLM-L6-v2\n",
    "\n",
    "\n",
    "#note: normalement pas besoin d'avoir le model sur l'ordi, il suffit de mettre le nom 'all-MiniLM-L6-v2' et SentenceTransformer va le chercher tout seul sur internet, mais là il y a un bug genre ajd, \n",
    "#donc j'ai téléchargé le model sur mon ordi et mis le path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\pretrained_model') #with model all-MiniLM-L6-v2' # or use 'bert-base-nli-mean-tokens'\n",
    "\n",
    "\n",
    "#Extract a small part of the whole file to test \n",
    "path = r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\quotes-2020-precessed.json.bz2' #path de mon ordi\n",
    "test = pd.DataFrame(columns=('qids','quotation'))\n",
    "i = 0\n",
    "with bz2.open(path, 'rb') as s_file:\n",
    "  for instance in s_file:\n",
    "    instance = json.loads(instance) \n",
    "    print(instance)\n",
    "    #print(instance['quotation'])\n",
    "    i = i + 1\n",
    "    test = test.append({'quoteID': instance['quoteID'], 'quotation': instance['quotation']}, ignore_index=True)\n",
    "    #print(i)\n",
    "    if i == 10:\n",
    "      break\n",
    "\n",
    "#embedding des 10 citations\n",
    "sentence_embeddings = model.encode(test['quotation'])\n",
    "\n",
    "#comparaison avec une des phrase du paper: cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "to_compare = [\"I'm sure it's\"]\n",
    "to_compare_embedding = model.encode(to_compare)\n",
    "\n",
    "cosine_similarity(\n",
    "    [to_compare_embedding[0]],\n",
    "    sentence_embeddings[0:]\n",
    ")\n",
    "\n",
    "#l'output ets un array des coefficients de similarité (là ils osnt tous ba vu qu'aucune citation n'a un truc prche de I'm sure it's)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### encore des tests pour voir si ça marche bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7573065 , 0.02370122, 0.0167593 , 0.07905838, 0.12434015,\n",
       "        0.13122094, 0.01477368, 0.07131456, 0.1100079 , 0.1029016 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison avec le début de la premiere citation pour checker qu'elle a alors bien un score élevé\n",
    "to_compare_2 = [\"Department of Homeland Security was livid and\"]\n",
    "to_compare_2_embedding = model.encode(to_compare_2)\n",
    "\n",
    "cosine_similarity(\n",
    "    [to_compare_2_embedding[0]],\n",
    "    sentence_embeddings[0:]\n",
    ")\n",
    "#le premier est bien plus élevé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.17984062]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison avec 2 trucs trés proches\n",
    "to_compare_3 = [\"I'm sure\"]\n",
    "to_compare_3_embedding = model.encode(to_compare_3)\n",
    "sentence_2 = [\"I'm sure it will be OK\"]\n",
    "sentence_2_embedding = model.encode(sentence_2)\n",
    "\n",
    "cosine_similarity(\n",
    "    [to_compare_3_embedding[0]],\n",
    "    sentence_2_embedding[0:]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19524246]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test de comparaison avec 2 synonymes\n",
    "to_compare_3 = [\"I can be wrong\"]\n",
    "to_compare_3_embedding = model.encode(to_compare_3)\n",
    "sentence_2 = [\"I am mistaken coucou love\"] #vrae faf feafq fezfaZF vzev ffreyhju j'ythgz azerazefg rt rt  r zeardcre grtuhy thzrg area etzttrh trhtrbg er ezt ery gt areer fraef dgc r e zger \n",
    "sentence_2_embedding = model.encode(sentence_2)\n",
    "\n",
    "cosine_similarity(\n",
    "    [to_compare_3_embedding[0]],\n",
    "    sentence_2_embedding[0:]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Project_2_.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
