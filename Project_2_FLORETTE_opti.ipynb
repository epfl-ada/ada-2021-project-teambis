{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "453eb2b0-9838-4ec0-b299-9fe540e8cde1",
   "metadata": {},
   "source": [
    "### Optimisation du code en cours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254523fb-c220-426b-8994-9d595bd7f50b",
   "metadata": {
    "id": "dnXvjWR9NWvZ"
   },
   "source": [
    "#### Mount the Google Drive in order to access to the files which are located on our drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "196be653-60e0-4541-adc0-0d0abb206bca",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CEcIlRwfWY4C",
    "outputId": "b4c9cb6a-9c53-45c1-ad98-a68c6550c2bd"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive._mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26816dfc-3940-4b28-a827-cf165e9ac4a6",
   "metadata": {
    "id": "5E6s11nPpS1S"
   },
   "source": [
    "#### Install and import every packages that will be necessary for the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39d3a37a-79f6-4ff8-8228-c4ce091d2482",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WDFHjZ-DpMXi",
    "outputId": "5ac51208-9817-41c8-a3c9-d8830978e78d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pickle-mixin in c:\\users\\flore\\anaconda3\\lib\\site-packages (1.0.2)\n",
      "Requirement already satisfied: pyarrow in c:\\users\\flore\\anaconda3\\lib\\site-packages (6.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\flore\\anaconda3\\lib\\site-packages (from pyarrow) (1.20.1)\n",
      "Requirement already satisfied: pathlib in c:\\users\\flore\\anaconda3\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pickle-mixin\n",
    "!pip install pyarrow\n",
    "!pip install pathlib\n",
    "\n",
    "\n",
    "import pyarrow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import bz2\n",
    "import json\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0811bf8-cbbe-45dc-b555-f6dfc17515b7",
   "metadata": {
    "id": "cx0MEzbZw5NM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dbaa13-b1c8-4f26-a91c-cb3c6cb0e7a5",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a3e1b4-440e-43d0-a9a7-09246714bb8c",
   "metadata": {},
   "source": [
    "### Imports, et import du model qu'on utilise ( pour l'instant all-MiniLM-L6-v2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fd17776-f204-4679-8a35-71a36740f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#si besoin\n",
    "#pip install -U sentence-transformers\n",
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bd4fd7-15d7-4cc9-a926-110af75caa67",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iEXXUZjT4yN7",
    "outputId": "c638bc74-0576-40b7-b515-a8838a784bc1"
   },
   "outputs": [],
   "source": [
    "#NLP libraries\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "#from gensim.models import FastText #pas utilisé finalement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69eae75c-57b0-4a46-8653-d49982416256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#model = SentenceTransformer(r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\pretrained_model') #pour si la ligne d'en dessous ne marche pas, telecharger le model en local et mettre le path\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "\n",
    "# j'ai testé plysieurs models:\n",
    "\n",
    "# all-MiniLM-L6-v2: ça passe, treshold à 0.6 ?\n",
    "#'bert-base-nli-mean-tokens' : deprecated\n",
    "#all-mpnet-base-v2: ne se télécharge pas\n",
    "#multi-qa-mpnet-base-dot-v1: ne va pas, tous les scores sont trés haut meme pour 'truc contraires\n",
    "#multi-qa-distilbert-cos-v1: mouai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65138d83-f077-4975-a68d-fe52a1eaa50f",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909db10a-c7a9-498e-b908-66bb7f641257",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Comparaison des citations (morceau par morceau) aux expressions du paper, et création d'un dataframe avec qids, quote, sim_score_expression1, sim_score_expression2, ..., sim_score_expressionN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097d985d-c767-4907-9831-887fa0e604af",
   "metadata": {},
   "source": [
    "Je decoupe les citations. Pour chaque expression: je compare chaque morceau de la citation avec l'expression, ça donne un score de similarité pour chaque morceau: on prend le max (ou bien faire un teshold ? à voir).  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d73e041-8fe3-43a8-8b0c-f04256a8fb2b",
   "metadata": {},
   "source": [
    "#### Basé sur la technique du paper Sentence Similarity Techniques for Short vs Variable Length Text using Word Embeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4657dc5f-fca8-4ab3-936d-fe671765bb63",
   "metadata": {},
   "source": [
    "#### Extract a small part of the whole quotes file to test (j'ai pas le vrai fichier pre procéssé, c'est pour ça qu'il y a des [ ] dans les citations, mais ça marchera pareil avec le bon fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8787efbe-29cc-469a-8430-79276a0b6a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract a small part of the whole file to test \n",
    "path = r'C:\\Users\\flore\\Desktop\\EPFL\\MA1\\ada\\PROJET\\quotes-processed.json.bz2' #path florette\n",
    "quotes = pd.DataFrame(columns=('qids','quotation'))\n",
    "i = 0\n",
    "with bz2.open(path, 'rb') as s_file:\n",
    "  for instance in s_file:\n",
    "    instance = json.loads(instance) \n",
    "    #print(instance)\n",
    "    #print(instance['quotation'])\n",
    "    i = i + 1\n",
    "    quotes = quotes.append({'qids': instance['qids'], 'quotation': instance['quotation']}, ignore_index=True)\n",
    "    #print(i)\n",
    "    if i == 10:\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17308254-069a-4cf4-bee3-100e218ed6d0",
   "metadata": {},
   "source": [
    "#### append some quotation for testing the efficacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bbce772-f908-4b75-9d25-0bb428cf05db",
   "metadata": {},
   "outputs": [],
   "source": [
    "quotes = quotes.append({'qids': 'Qtest1', 'quotation': 'I know it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest2', 'quotation': 'I dont know if it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest3', 'quotation': 'I am sure it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest4', 'quotation': 'I am not sure if it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest5', 'quotation': 'I dont eat an apple'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest6', 'quotation': 'I pretty sure if it is a fool'}, ignore_index=True)\n",
    "quotes = quotes.append({'qids': 'Qtest7', 'quotation': 'I was sure if it is a fool'}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53718a-cae3-4846-bdf1-db1e708c1be9",
   "metadata": {},
   "source": [
    "#### create a dataframe de test with the expression we want to compare, and their score (remplacer aprés avec le vrai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f49366b4-22b8-4179-85ee-6239d726b541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expression</th>\n",
       "      <th>expression_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm not sure</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dont know</td>\n",
       "      <td>3.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I suppose</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     expression  expression_score\n",
       "0  I'm not sure              2.91\n",
       "1   I dont know              3.02\n",
       "2     I suppose              3.34"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a dataframe with the ewpression we want to compare, and their score\n",
    "expressions = pd.DataFrame({'expression': [\"I'm not sure\", \"I dont know\", \"I suppose\", \"I think\", \"I'm sure\", \"I know\"], 'expression_score': [2.91, 3.02, 3.34, 3.48, 6.02, 6.45]})\n",
    "expressions.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed76ac4a-bb9a-419d-b49c-f055906b53cd",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca6d07-ca37-4ec1-9404-1e904670dadd",
   "metadata": {},
   "source": [
    "### Comparaison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9063b796-eff4-4e62-b0d2-3fb51d955464",
   "metadata": {},
   "source": [
    "#### Chunker les citations pour découper en un certain nombre de mots (j'ai pas trouvé de méthode optimale, alors je tokenize en mots, puis je join le nombre de mots qu'on veut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1faf11d-5dea-4a73-acc9-4fe3f6e8fc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qids</th>\n",
       "      <th>quotation</th>\n",
       "      <th>n_grams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>Department of Homeland Security was livid and ...</td>\n",
       "      <td>[Department of Homeland, of Homeland Security,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>I met them when they just turned 4 and 7. They...</td>\n",
       "      <td>[I met them, met them when, them when they, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>The delay will have an impact on Slough but th...</td>\n",
       "      <td>[The delay will, delay will have, will have an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Q4864119]</td>\n",
       "      <td>The scheme treats addiction as an illness and ...</td>\n",
       "      <td>[The scheme treats, scheme treats addiction, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Q816459]</td>\n",
       "      <td>These actions will allow households who have a...</td>\n",
       "      <td>[These actions will, actions will allow, will ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Q30164281]</td>\n",
       "      <td>1. FM is entitled to go straight to press conf...</td>\n",
       "      <td>[1 . FM, . FM is, FM is entitled, is entitled ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Q56255401]</td>\n",
       "      <td>11 straight weeks of pre-season,</td>\n",
       "      <td>[11 straight weeks, straight weeks of, weeks o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Q26923564]</td>\n",
       "      <td>2019 was a landmark year for Fiverr as we comp...</td>\n",
       "      <td>[2019 was a, was a landmark, a landmark year, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Q4749380]</td>\n",
       "      <td>7pm is when most hospitals change shifts. That...</td>\n",
       "      <td>[7pm is when, is when most, when most hospital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Q970000]</td>\n",
       "      <td>A city is not an accident but the result of co...</td>\n",
       "      <td>[A city is, city is not, is not an, not an acc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qtest1</td>\n",
       "      <td>I know it is a fool</td>\n",
       "      <td>[I know it, know it is, it is a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qtest2</td>\n",
       "      <td>I dont know if it is a fool</td>\n",
       "      <td>[I dont know, dont know if, know if it, if it ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qtest3</td>\n",
       "      <td>I am sure it is a fool</td>\n",
       "      <td>[I am sure, am sure it, sure it is, it is a]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qtest4</td>\n",
       "      <td>I am not sure if it is a fool</td>\n",
       "      <td>[I am not, am not sure, not sure if, sure if i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qtest5</td>\n",
       "      <td>I dont eat an apple</td>\n",
       "      <td>[I dont eat, dont eat an]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qtest6</td>\n",
       "      <td>I pretty sure if it is a fool</td>\n",
       "      <td>[I pretty sure, pretty sure if, sure if it, if...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Qtest7</td>\n",
       "      <td>I was sure if it is a fool</td>\n",
       "      <td>[I was sure, was sure if, sure if it, if it is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           qids                                          quotation  \\\n",
       "0     [Q367796]  Department of Homeland Security was livid and ...   \n",
       "1   [Q20684375]  I met them when they just turned 4 and 7. They...   \n",
       "2    [Q5268447]  The delay will have an impact on Slough but th...   \n",
       "3    [Q4864119]  The scheme treats addiction as an illness and ...   \n",
       "4     [Q816459]  These actions will allow households who have a...   \n",
       "5   [Q30164281]  1. FM is entitled to go straight to press conf...   \n",
       "6   [Q56255401]                   11 straight weeks of pre-season,   \n",
       "7   [Q26923564]  2019 was a landmark year for Fiverr as we comp...   \n",
       "8    [Q4749380]  7pm is when most hospitals change shifts. That...   \n",
       "9     [Q970000]  A city is not an accident but the result of co...   \n",
       "10       Qtest1                                I know it is a fool   \n",
       "11       Qtest2                        I dont know if it is a fool   \n",
       "12       Qtest3                             I am sure it is a fool   \n",
       "13       Qtest4                      I am not sure if it is a fool   \n",
       "14       Qtest5                                I dont eat an apple   \n",
       "15       Qtest6                      I pretty sure if it is a fool   \n",
       "16       Qtest7                         I was sure if it is a fool   \n",
       "\n",
       "                                              n_grams  \n",
       "0   [Department of Homeland, of Homeland Security,...  \n",
       "1   [I met them, met them when, them when they, wh...  \n",
       "2   [The delay will, delay will have, will have an...  \n",
       "3   [The scheme treats, scheme treats addiction, t...  \n",
       "4   [These actions will, actions will allow, will ...  \n",
       "5   [1 . FM, . FM is, FM is entitled, is entitled ...  \n",
       "6   [11 straight weeks, straight weeks of, weeks o...  \n",
       "7   [2019 was a, was a landmark, a landmark year, ...  \n",
       "8   [7pm is when, is when most, when most hospital...  \n",
       "9   [A city is, city is not, is not an, not an acc...  \n",
       "10                   [I know it, know it is, it is a]  \n",
       "11  [I dont know, dont know if, know if it, if it ...  \n",
       "12       [I am sure, am sure it, sure it is, it is a]  \n",
       "13  [I am not, am not sure, not sure if, sure if i...  \n",
       "14                          [I dont eat, dont eat an]  \n",
       "15  [I pretty sure, pretty sure if, sure if it, if...  \n",
       "16  [I was sure, was sure if, sure if it, if it is...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimisé\n",
    "#First, we separate the word and symbol using tokenisation. This will allow us to then reform n_grams with the desired number of words/symbol.\n",
    "quotes['n_grams'] = quotes['quotation'].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "#Then reform chunk of n words\n",
    "n = 4 #number in n_gram\n",
    "quotes['n_grams'] = quotes['n_grams'].apply(lambda x: (list(\" \".join(x[i : i+n-1]) for i in range(len(x) - n + 1))))\n",
    "quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbea7db-10a2-4d59-a92b-c54c3b7d1910",
   "metadata": {},
   "source": [
    "#### Compare the citations chunk with the expressions and add the comparison score = cosinus similarity (max score for the different chunk) in a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "509f836a-4229-4fe1-b469-20488593ae3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qids</th>\n",
       "      <th>quotation</th>\n",
       "      <th>n_grams</th>\n",
       "      <th>cosine_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Q367796]</td>\n",
       "      <td>Department of Homeland Security was livid and ...</td>\n",
       "      <td>[Department of Homeland, of Homeland Security,...</td>\n",
       "      <td>[0.3032319, 0.3031956, 0.23602816, 0.22850059,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Q20684375]</td>\n",
       "      <td>I met them when they just turned 4 and 7. They...</td>\n",
       "      <td>[I met them, met them when, them when they, wh...</td>\n",
       "      <td>[0.2303027, 0.2367206, 0.27510583, 0.29699588,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Q5268447]</td>\n",
       "      <td>The delay will have an impact on Slough but th...</td>\n",
       "      <td>[The delay will, delay will have, will have an...</td>\n",
       "      <td>[0.41248465, 0.34659547, 0.50099874, 0.6188506...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Q4864119]</td>\n",
       "      <td>The scheme treats addiction as an illness and ...</td>\n",
       "      <td>[The scheme treats, scheme treats addiction, t...</td>\n",
       "      <td>[0.27248415, 0.21348144, 0.23313306, 0.2357903...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Q816459]</td>\n",
       "      <td>These actions will allow households who have a...</td>\n",
       "      <td>[These actions will, actions will allow, will ...</td>\n",
       "      <td>[0.2834597, 0.28215024, 0.22757119, 0.18103966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[Q30164281]</td>\n",
       "      <td>1. FM is entitled to go straight to press conf...</td>\n",
       "      <td>[1 . FM, . FM is, FM is entitled, is entitled ...</td>\n",
       "      <td>[0.29281023, 0.25658804, 0.33833924, 0.2641971...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[Q56255401]</td>\n",
       "      <td>11 straight weeks of pre-season,</td>\n",
       "      <td>[11 straight weeks, straight weeks of, weeks o...</td>\n",
       "      <td>[0.1850446, 0.1714744, 0.13752353, 0.18754275,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[Q26923564]</td>\n",
       "      <td>2019 was a landmark year for Fiverr as we comp...</td>\n",
       "      <td>[2019 was a, was a landmark, a landmark year, ...</td>\n",
       "      <td>[0.2398042, 0.22135988, 0.18565738, 0.25002772...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[Q4749380]</td>\n",
       "      <td>7pm is when most hospitals change shifts. That...</td>\n",
       "      <td>[7pm is when, is when most, when most hospital...</td>\n",
       "      <td>[0.26984522, 0.27745345, 0.3020717, 0.23797627...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[Q970000]</td>\n",
       "      <td>A city is not an accident but the result of co...</td>\n",
       "      <td>[A city is, city is not, is not an, not an acc...</td>\n",
       "      <td>[0.31056875, 0.28648853, 0.2216119, 0.25278366...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Qtest1</td>\n",
       "      <td>I know it is a fool</td>\n",
       "      <td>[I know it, know it is, it is a]</td>\n",
       "      <td>[0.28771922, 0.25129408, 0.3063254, 0.3667931,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Qtest2</td>\n",
       "      <td>I dont know if it is a fool</td>\n",
       "      <td>[I dont know, dont know if, know if it, if it ...</td>\n",
       "      <td>[0.75919974, 1.0000002, 0.4207487, 0.44757956,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Qtest3</td>\n",
       "      <td>I am sure it is a fool</td>\n",
       "      <td>[I am sure, am sure it, sure it is, it is a]</td>\n",
       "      <td>[0.52528226, 0.41856447, 0.5605824, 0.4690525,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Qtest4</td>\n",
       "      <td>I am not sure if it is a fool</td>\n",
       "      <td>[I am not, am not sure, not sure if, sure if i...</td>\n",
       "      <td>[0.8502275, 0.68310356, 0.3907313, 0.46808985,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Qtest5</td>\n",
       "      <td>I dont eat an apple</td>\n",
       "      <td>[I dont eat, dont eat an]</td>\n",
       "      <td>[0.16147041, 0.19534802, 0.100145936, 0.065757...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Qtest6</td>\n",
       "      <td>I pretty sure if it is a fool</td>\n",
       "      <td>[I pretty sure, pretty sure if, sure if it, if...</td>\n",
       "      <td>[0.6306063, 0.5200125, 0.6445842, 0.65489495, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Qtest7</td>\n",
       "      <td>I was sure if it is a fool</td>\n",
       "      <td>[I was sure, was sure if, sure if it, if it is...</td>\n",
       "      <td>[0.42896688, 0.2954333, 0.4197359, 0.3667931, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           qids                                          quotation  \\\n",
       "0     [Q367796]  Department of Homeland Security was livid and ...   \n",
       "1   [Q20684375]  I met them when they just turned 4 and 7. They...   \n",
       "2    [Q5268447]  The delay will have an impact on Slough but th...   \n",
       "3    [Q4864119]  The scheme treats addiction as an illness and ...   \n",
       "4     [Q816459]  These actions will allow households who have a...   \n",
       "5   [Q30164281]  1. FM is entitled to go straight to press conf...   \n",
       "6   [Q56255401]                   11 straight weeks of pre-season,   \n",
       "7   [Q26923564]  2019 was a landmark year for Fiverr as we comp...   \n",
       "8    [Q4749380]  7pm is when most hospitals change shifts. That...   \n",
       "9     [Q970000]  A city is not an accident but the result of co...   \n",
       "10       Qtest1                                I know it is a fool   \n",
       "11       Qtest2                        I dont know if it is a fool   \n",
       "12       Qtest3                             I am sure it is a fool   \n",
       "13       Qtest4                      I am not sure if it is a fool   \n",
       "14       Qtest5                                I dont eat an apple   \n",
       "15       Qtest6                      I pretty sure if it is a fool   \n",
       "16       Qtest7                         I was sure if it is a fool   \n",
       "\n",
       "                                              n_grams  \\\n",
       "0   [Department of Homeland, of Homeland Security,...   \n",
       "1   [I met them, met them when, them when they, wh...   \n",
       "2   [The delay will, delay will have, will have an...   \n",
       "3   [The scheme treats, scheme treats addiction, t...   \n",
       "4   [These actions will, actions will allow, will ...   \n",
       "5   [1 . FM, . FM is, FM is entitled, is entitled ...   \n",
       "6   [11 straight weeks, straight weeks of, weeks o...   \n",
       "7   [2019 was a, was a landmark, a landmark year, ...   \n",
       "8   [7pm is when, is when most, when most hospital...   \n",
       "9   [A city is, city is not, is not an, not an acc...   \n",
       "10                   [I know it, know it is, it is a]   \n",
       "11  [I dont know, dont know if, know if it, if it ...   \n",
       "12       [I am sure, am sure it, sure it is, it is a]   \n",
       "13  [I am not, am not sure, not sure if, sure if i...   \n",
       "14                          [I dont eat, dont eat an]   \n",
       "15  [I pretty sure, pretty sure if, sure if it, if...   \n",
       "16  [I was sure, was sure if, sure if it, if it is...   \n",
       "\n",
       "                                    cosine_similarity  \n",
       "0   [0.3032319, 0.3031956, 0.23602816, 0.22850059,...  \n",
       "1   [0.2303027, 0.2367206, 0.27510583, 0.29699588,...  \n",
       "2   [0.41248465, 0.34659547, 0.50099874, 0.6188506...  \n",
       "3   [0.27248415, 0.21348144, 0.23313306, 0.2357903...  \n",
       "4   [0.2834597, 0.28215024, 0.22757119, 0.18103966...  \n",
       "5   [0.29281023, 0.25658804, 0.33833924, 0.2641971...  \n",
       "6   [0.1850446, 0.1714744, 0.13752353, 0.18754275,...  \n",
       "7   [0.2398042, 0.22135988, 0.18565738, 0.25002772...  \n",
       "8   [0.26984522, 0.27745345, 0.3020717, 0.23797627...  \n",
       "9   [0.31056875, 0.28648853, 0.2216119, 0.25278366...  \n",
       "10  [0.28771922, 0.25129408, 0.3063254, 0.3667931,...  \n",
       "11  [0.75919974, 1.0000002, 0.4207487, 0.44757956,...  \n",
       "12  [0.52528226, 0.41856447, 0.5605824, 0.4690525,...  \n",
       "13  [0.8502275, 0.68310356, 0.3907313, 0.46808985,...  \n",
       "14  [0.16147041, 0.19534802, 0.100145936, 0.065757...  \n",
       "15  [0.6306063, 0.5200125, 0.6445842, 0.65489495, ...  \n",
       "16  [0.42896688, 0.2954333, 0.4197359, 0.3667931, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#optimisé\n",
    "\n",
    "#quotes['cosine_similarity'] = quotes['n_grams'].apply(lambda x: list(max(cosine_similarity([n_gram_embedded], [expression_embedded]) for n_gram_embedded in model.encode(x)) for expression_embedded in model.encode(expressions.expression)))\n",
    "#quotes['cosine_similarity'] = quotes['n_grams'].apply(lambda x: list(max(cosine_similarity([n_gram_embedded], [expression_embedded]) for n_gram_embedded in model.encode(x)).flatten() for expression_embedded in model.encode(expressions.expression)))\n",
    "\n",
    "quotes['cosine_similarity'] = quotes['n_grams'].apply(lambda x: list(max(cosine_similarity([n_gram_embedded], [expression_embedded]) for n_gram_embedded in model.encode(x)).flatten()[0] for expression_embedded in model.encode(expressions.expression)))\n",
    "\n",
    "\n",
    "#test pour direct mettre dans des colonnes séparées mais pas encore trouvé comment faire\n",
    "#quotes['n_grams'].apply(lambda x: quotes[expressions.expression] <- (max(cosine_similarity([n_gram_embedded], [expression_embedded]) for n_gram_embedded in model.encode(x))) for expression_embedded in model.encode(expressions.expression))\n",
    "\n",
    "quotes.head(20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "022b386d-8ca3-4b35-9792-61975dbdd08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(quotes_similarity.iloc[10:20])#pour ettre chaque score dans une colonne nomée par le nom de la citation\n",
    "#for exp in zip(expressions.expression, range(len(expressions.expression))):\n",
    "#    quotes['exp'] = quotes.cosine_similarity\n",
    "#quotes.head(20)\n",
    "\n",
    "#df_max_cos_sim = pd.DataFrame(index=(\"I'm not sure\", \"I dont know\", \"I suppose\", \"I think\", \"I'm sure\", \"I know\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953f337-eec1-4773-ade1-5ad3d05eebb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
